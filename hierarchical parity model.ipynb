{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Parity Model\n",
    "\n",
    "This notebook is used to calculate quantities of interest for the hierarchical parity model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## imports\n",
    "import time\n",
    "import scipy\n",
    "from scipy.stats import sem\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import numpy as onp #o for \"old\" or \"original\"\n",
    "import jax.numpy as np\n",
    "import jax\n",
    "from jax import grad, jit, lax, random, ops, vmap, jacfwd, jacrev, device_get, device_put\n",
    "from jax.scipy.special import logsumexp\n",
    "from jax.lib import xla_bridge\n",
    "from tqdm.notebook import tqdm\n",
    "#jax.local_devices()\n",
    "import utils\n",
    "\n",
    "rng = onp.random.default_rng(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## matplotlib settings\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "plt.rcParams['font.size'] = '14'\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.serif'] = ['Computer Modern']\n",
    "\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "plt.rcParams[\"axes.edgecolor\"] = \"black\"\n",
    "\n",
    "plt.rcParams['text.color'] = 'k'\n",
    "plt.rcParams['axes.labelcolor'] = 'k'\n",
    "plt.rcParams['xtick.color'] = 'k'\n",
    "plt.rcParams['ytick.color'] = 'k'\n",
    "\n",
    "plt.rcParams['xtick.major.size'] = 15\n",
    "plt.rcParams['xtick.major.width'] = 1\n",
    "plt.rcParams['ytick.major.size'] = 15\n",
    "plt.rcParams['ytick.major.width'] = 1\n",
    "\n",
    "plt.rcParams['xtick.minor.size'] = 7\n",
    "plt.rcParams['xtick.minor.width'] = 1\n",
    "plt.rcParams['ytick.minor.size'] = 7\n",
    "plt.rcParams['ytick.minor.width'] = 1\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "abcs = ['(a)', '(b)', '(c)', '(d)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a data directory if one does not already exist\n",
    "if not os.path.exists('data'):\n",
    "    os.mkdir('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Degeneracy\n",
    "\n",
    "Numerically verify the degeneracy of the model for a few different cases. First, examine the ground state (gs) degeneracy of the uniform model. The gs degeneracy of the uniform model with ferromagnetic couplings $(J>0)$ is trivial: there is always a unique ground state. However, there is an extensive gs degeneracy for the uniform model with anti-ferromagnetic couplings that obeys an interesting recursion relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## there is a unique gs for the ferromagnetic case\n",
    "## output is of the form (gs energy, gs degenercy)\n",
    "utils.compute_uniform_gs_degen(4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the gs degeneracy obeys an interesting pattern for the anti-ferromagnetic case\n",
    "for k in range(5):\n",
    "    print('k = %i' %k)\n",
    "    print('gs energy (total)', utils.compute_uniform_gs_degen(k, -1))\n",
    "    print('gs energy (parity = 1)', utils.compute_uniform_gs_degen(k, -1, parity=1))\n",
    "    print('gs energy (parity = -1)', utils.compute_uniform_gs_degen(k, -1, parity=-1))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can derive recursion relations that explain the above pattern. Let $N = 2^k$, with $k=0,1,...$. Also let $d_k$ be the ground state degeneracy, and $d_k^{\\pm}$ the degeneracy of the lowest energy states with parity = $+1$ or $-1$. Note that the lowest energy state of a given parity may or may not be a ground state. \n",
    "\n",
    "For $N = 1$, $k=0$, the degeneracies are all 1 as there is just a single state. Then the recursion relations are:\n",
    "\n",
    "$$ \n",
    "d_{k}^- = 2 d_{k-1}^- d_{k-1}^+ \\, \\qquad d_k^+ = \\begin{cases} (d_{k-1}^-)^2 & k \\text{ odd} \\\\ (d_{k-1}^-)^2 + (d_{k-1}^+)^2 & k \\text{ even} \\end{cases} \n",
    "$$\n",
    "\n",
    "From this the full degenaracy can be worked out. For $k$ even only the negative parity lowest energy states are actual ground states, whereas for $k$ odd both sets of states are ground states. So,\n",
    "\n",
    "$$ \n",
    "d_k = \\begin{cases} d_k^- + d_k^+ & k \\text{ odd} \\\\ d_k^- & k \\text{ even} \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The degeneracy grows so fast that numerical overflow is reached very quickly. Therefore, it will be convenient to implement the recursion relations in terms of the log degeneracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check\n",
    "n = 6\n",
    "deg = utils.degeneracy(n)\n",
    "log_deg = utils.log_degeneracy(n)\n",
    "\n",
    "for s in ['minus', 'plus', 'full']:\n",
    "    print('Check degeneracy type %s: %r' %(s, onp.allclose(onp.log(onp.asarray(list(deg[s].values())))/onp.log(2), onp.asarray(list(log_deg[s].values())))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The degeneracy grows exponentially in $N$: $d_k \\sim b^N$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 70\n",
    "log_deg = utils.log_degeneracy(n)\n",
    "\n",
    "Nvalues = 2.0**onp.asarray(list(log_deg['minus'].keys()))\n",
    "log_deg_values = onp.asarray(list(log_deg['full'].values()))\n",
    "log_deg_plus_values = onp.asarray(list(log_deg['plus'].values()))\n",
    "log_deg_minus_values = onp.asarray(list(log_deg['minus'].values()))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(Nvalues, log_deg_values, '-o')\n",
    "ax.set_xlabel('N')\n",
    "ax.set_ylabel('log deg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a linear fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, b = onp.polyfit(Nvalues[15:], log_deg_values[15:], 1)\n",
    "m, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the fit depend on whether $k$ is even or odd?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odd_indices = onp.asarray([2*i + 1 for i in range(15,30)])\n",
    "even_indices = onp.asarray([2*i for i in range(15,30)])\n",
    "\n",
    "m, b = onp.polyfit(Nvalues[odd_indices], log_deg_values[odd_indices], 1)\n",
    "print('(even) slope = %.6f, y_intercept = %.6f' %(m,b))\n",
    "print('dk grows like A * b^N, with A = %.4f, b = %.4f' % (2**b, 2**m))\n",
    "\n",
    "m, b = onp.polyfit(Nvalues[even_indices], log_deg_values[even_indices], 1)\n",
    "print('\\n(even) slope = %.6f, y_intercept = %.6f' %(m,b))\n",
    "print('dk grows like A * b^N, with A = %.4f, b = %.4f' % (2**b, 2**m))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will also be useful to be able to compute the spectrum for a system of arbitrary couplings. This can be used to verify that a spin system at level $n$ with no single-spin couplings is equivalent to a spin system at level $n-1$ with a $2^{2^{n-1}}$-fold degeneracy for each state. The subtle part here is to ensure that the couplings of the smaller system match up with the couplings of the larger system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## n = 3 case\n",
    "n = 3\n",
    "N = 2**n\n",
    "leaf_indices = [3,4,6,7,10,11,13,14] #these should have zero couplings in the larger system\n",
    "\n",
    "couplings_large = rng.integers(low=-100000, high=100000, size=2*N-1)\n",
    "couplings_large = onp.asarray([(i not in leaf_indices)*couplings_large[i] for i in range(len(couplings_large))])\n",
    "couplings_small = onp.asarray([c for c in couplings_large if c!=0])\n",
    "\n",
    "spec_large = utils.compute_spectrum(couplings_large)\n",
    "spec_small = utils.compute_spectrum(couplings_small)\n",
    "\n",
    "print('Do the sets of unique energies agree: %r' %(spec_large.keys() == spec_small.keys()))\n",
    "print('Are the degeneracies all 2^(N/2)=%i? %r' % (2**(N/2), 2**(N/2) == onp.unique(onp.asarray(list(spec_large.values())))[0] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## n = 4 case\n",
    "n = 4\n",
    "N = 2**n\n",
    "leaf_indices = [4,5,7,8,11,12,14,15,19,20,22,23,26,27,29,30] #these should have zero couplings in the larger system\n",
    "\n",
    "couplings_large = rng.integers(low=-100000, high=100000, size=2*N-1)\n",
    "couplings_large = onp.asarray([(i not in leaf_indices)*couplings_large[i] for i in range(len(couplings_large))])\n",
    "couplings_small = onp.asarray([c for c in couplings_large if c!=0])\n",
    "\n",
    "spec_large = utils.compute_spectrum(couplings_large)\n",
    "spec_small = utils.compute_spectrum(couplings_small)\n",
    "\n",
    "print('Do the sets of unique energies agree: %r' %(spec_large.keys() == spec_small.keys()))\n",
    "print('Are the degeneracies all 2^(N/2)=%i? %r' % (2**(N/2), 2**(N/2) == onp.unique(onp.asarray(list(spec_large.values())))[0] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disordered Case\n",
    "\n",
    "First, verify that the GS function is correctly computing the ground state and its degeneracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute the GS energy and degeneracy using the O(N) algorithm\n",
    "n= 4\n",
    "couplings = utils.generate_couplings_dic(n, prob=0.5, sigma=0) # generate the couplings\n",
    "couplings = utils.coupling_dic_to_array(couplings) # sort them according to binary tree traversal pre-order (root, left, right)\n",
    "utils.GS(couplings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute the GS energy and degeneracy by brute force\n",
    "spec = utils.compute_spectrum(couplings)\n",
    "Egs = min(list(spec.keys()))\n",
    "deg = spec[Egs]\n",
    "print('Egs = %.2f, deg = %i' %(Egs, deg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the ground state energy and degeneracy for a number of random draws of the couplings. For this use $p=0.5$ and $\\sigma = 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nreplicas = 1000\n",
    "data = {}\n",
    "nlist = list(range(5,12))\n",
    "for n in nlist:\n",
    "    data_tmp = {'E':[], 'logd':[]}\n",
    "    for i in range(Nreplicas):\n",
    "        couplings = utils.generate_couplings_dic(n, prob=0.5, sigma=0.0) # generate the couplings\n",
    "        couplings = utils.coupling_dic_to_array(couplings) # sort them according to binary tree traversal pre-order (root, left, right)\n",
    "        gs = utils.GS(couplings)\n",
    "        data_tmp['E'].append(gs['E'])\n",
    "        data_tmp['logd'].append(gs['logd'])\n",
    "    data[n] = data_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the degeneracy in the uniform model obeys $d_n \\sim A b^N$, it is reasonable to expect a similar relation to hold in the disordered case:\n",
    "\n",
    "$$\\mathbb{E}_J \\log_2 d_k \\sim \\log_2 A + N \\, \\log_2 b \\,. $$\n",
    "\n",
    "Therefore, make a kernel density plot of $\\log_2 d_k/N$. The plot indicates a) that the mean is converging and b) that the standard deviation is decreasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "for n in nlist:\n",
    "    sns.kdeplot(onp.asarray(data[n]['logd']) /2**n, linewidth=2, label='n = %i'%n, fill=True)\n",
    "ax.set_xlabel(r'$\\log_2(d_k)/N$')\n",
    "plt.legend(fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same linear fit as for the uniform model, but this time with many samples per system size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nvalues = []\n",
    "log_deg_values = []\n",
    "for n in nlist:\n",
    "    for i in range(len(data[n]['logd'])):\n",
    "        Nvalues.append(2**n)\n",
    "        log_deg_values.append(data[n]['logd'][i])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(Nvalues, log_deg_values, '-o')\n",
    "ax.set_xlabel('N')\n",
    "ax.set_ylabel('log deg')\n",
    "plt.show()\n",
    "\n",
    "m, b = onp.polyfit(Nvalues, log_deg_values, 1)\n",
    "print('slope = %.6f, y_intercept = %.6f' %(m,b))\n",
    "print('dk grows like A * b^N, with A = %.4f, b = %.4f' % (2**b, 2**m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, do a linear fit but now average the log degeneracy across all samples for the same system size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nvalues = []\n",
    "log_deg_values = []\n",
    "for n in nlist:\n",
    "    Nvalues.append(2**n)\n",
    "    log_deg_values.append(onp.mean(data[n]['logd']))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(Nvalues, log_deg_values, '-o')\n",
    "ax.set_xlabel('N')\n",
    "ax.set_ylabel('log deg')\n",
    "plt.show()\n",
    "\n",
    "m, b = onp.polyfit(Nvalues, log_deg_values, 1)\n",
    "print('slope = %.6f, y_intercept = %.6f' %(m,b))\n",
    "print('dk grows like A * b^N, with A = %.4f, b = %.4f' % (2**b, 2**m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, estimate $\\mathbb{E}_J \\log_2 b$ as a function of $p$, where $p$ is the probability that an edge is ferromagnetic and $(1-p)$ is the probability that it is anti-ferromagnetic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def degeneracy_growth_rate_estimator(prob=0.5, sigma=0.0, Nsamples=1000, nlist=[3,4,5,6,7,8]):\n",
    "    '''\n",
    "    Scan over Nsamples realizations of the disordered system for a range of system sizes.\n",
    "    From this, compute the average log degeneracy and then perform a linear fit, allowing \n",
    "    for the base b to be extracted in the exponential growth.\n",
    "    '''\n",
    "    data = {}\n",
    "    Nvalues = []\n",
    "    log_deg_values = []\n",
    "    \n",
    "    ## scan over system sizes\n",
    "    for n in nlist:\n",
    "        Nvalues.append(2**n)\n",
    "        data_tmp = {'E':[], 'logd':[]}\n",
    "\n",
    "        ## scan over samples\n",
    "        for i in range(Nsamples):\n",
    "            couplings = utils.generate_couplings_dic(n, prob=prob, sigma=sigma) # generate the couplings\n",
    "            couplings = utils.coupling_dic_to_array(couplings) # sort them according to binary tree traversal pre-order (root, left, right)\n",
    "            gs = utils.GS(couplings)\n",
    "            data_tmp['E'].append(gs['E'])\n",
    "            data_tmp['logd'].append(gs['logd'])\n",
    "        data[n] = data_tmp\n",
    "        log_deg_values.append(onp.mean(data[n]['logd'])) \n",
    "\n",
    "    ## perform the linear fit\n",
    "    slope, y_intercept = onp.polyfit(Nvalues, log_deg_values, 1)\n",
    "    return {'A':2**y_intercept, 'b':2**slope}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now make the plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plist = onp.linspace(0.01, 0.99, 50)\n",
    "y = [degeneracy_growth_rate_estimator(prob=p, sigma=0, Nsamples=1000)['b'] for p in plist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "ax.plot(plist, y, '-o', color='k')\n",
    "ax.set_xlabel(r'$p$', fontsize=18)\n",
    "ax.set_ylabel(r'$b$', fontsize=18)\n",
    "ax.grid(b=True, which='major', color='k', linestyle='--')\n",
    "ax.set_xlim([0,1])\n",
    "ax.set_ylim([1,1.6])\n",
    "plt.savefig('figures/disordered_model_bfit.pdf', bbox_inches='tight', pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary-Based (Non-Auto-Diff) Code\n",
    "\n",
    "This code is based on using dictionaries, it's much faster than than the Jax code but doesn't allow for derivatives to be computed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 12\n",
    "print('N = %i spins' %(2**n))\n",
    "beta = 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the recursion relations to exactly compute the expectation of the parity operators, $\\langle P_{k,p} \\rangle$, for a range of temperatures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "couplings = utils.generate_couplings_dic(n)\n",
    "th_beta_list = np.flip(np.linspace(0.1, 0.9, 5))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(2*11,9))\n",
    "for i in range(len(th_beta_list)):\n",
    "    beta = np.arctanh(th_beta_list[i])\n",
    "    parities = utils.find_parities_dic(beta, couplings)\n",
    "    \n",
    "    #ax[0].hist(list(parities.values()), bins=100, label=r'$\\tanh(\\beta) = %.2f$' %th_beta_list[i])\n",
    "    sns.kdeplot(list(parities.values()), label=r'$\\tanh(\\beta) = %.2f$' %th_beta_list[i], ax=ax[0], bw_adjust=.1)\n",
    "    #sns.histplot(list(parities.values()), color=colors[i], label=r'$\\tanh(\\beta) = %.2f$' %th_beta_list[i], ax=ax[0])\n",
    "    ax[0].legend()\n",
    "    ax[0].set_title(r\"Distribution of $\\langle P_{k,p} \\rangle$\")\n",
    "    ax[0].set_xlabel(r'$\\langle P_{k,p} \\rangle$')\n",
    "    ax[1].set_ylabel('Density')\n",
    "    \n",
    "    sns.kdeplot(list(parities.values()), label=r'$\\tanh(\\beta) = %.2f$' %th_beta_list[i], ax=ax[1], bw_adjust=.1, cumulative=True)\n",
    "    #ax[1].legend()\n",
    "    ax[1].set_title(r\"Cumulative Distribution of $\\langle P_{k,p} \\rangle$\")\n",
    "    ax[1].set_xlabel(r'$\\langle P_{k,p} \\rangle$')\n",
    "    ax[1].set_ylabel('Cumulative Density')\n",
    "    \n",
    "plt.savefig('figures/disordered_model_parity_distribution.pdf', bbox_inches='tight', pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jax Auto-Diff Code\n",
    "\n",
    "This section uses Jax's autodiff capability to compute quantities expressible as derivatives of the partition function (such as the energy, entropy, or heat capacity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thermodynamic Limit\n",
    "\n",
    "Inspect convergence as thermodynamic limit is approached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_disorder = 100\n",
    "n_list = [i for i in range(3,10)]\n",
    "\n",
    "th_beta_list = np.linspace(0.05, 0.95, 20)\n",
    "sigma = 0.0\n",
    "prob = 0.5\n",
    "\n",
    "if os.path.exists('data/f_list_sizescan.npy'):\n",
    "    print('data already exists, loading')\n",
    "    f_list = np.load('data/f_list_sizescan.npy')\n",
    "    e_list = np.load('data/e_list_sizescan.npy')\n",
    "    s_list = np.load('data/s_list_sizescan.npy')\n",
    "    c_list = np.load('data/c_list_sizescan.npy')\n",
    "\n",
    "else:    \n",
    "    print('data does not already exist, processing')    \n",
    "    f_list = onp.zeros((len(n_list), n_disorder, len(th_beta_list)))\n",
    "    e_list = onp.zeros((len(n_list), n_disorder, len(th_beta_list)))\n",
    "    s_list = onp.zeros((len(n_list), n_disorder, len(th_beta_list)))\n",
    "    c_list = onp.zeros((len(n_list), n_disorder, len(th_beta_list)))\n",
    "    #chi_list = onp.zeros((len(n_list), n_disorder, len(th_beta_list)))\n",
    "\n",
    "    ## loop over different system sizes\n",
    "    for i_n in range(len(n_list)):\n",
    "        n = n_list[i_n]\n",
    "        N = 2**n\n",
    "        print('processing n = %i' %n)\n",
    "\n",
    "        ## loop over disorder replicas\n",
    "        for i in range(n_disorder):\n",
    "            couplings = utils.generate_couplings(n, prob=prob, sigma=sigma)\n",
    "\n",
    "            ## loop over temperatures\n",
    "            for j in range(len(th_beta_list)):\n",
    "                beta = np.arctanh(th_beta_list[j])\n",
    "\n",
    "                f_list[i_n, i, j] = utils.free_energy(beta, couplings).item()/N\n",
    "                e_list[i_n, i, j] = utils.energy(beta, couplings).item()/N\n",
    "                s_list[i_n, i, j] = utils.entropy(beta, couplings).item()/N\n",
    "                c_list[i_n, i, j] = utils.heat_capacity(beta, couplings).item()/N\n",
    "                #chi_list[i_n, i, j] = utils.chi_SG(beta, couplings).item()\n",
    "                \n",
    "    ## save the results\n",
    "    np.save('data/f_list_sizescan.npy', f_list)\n",
    "    np.save('data/e_list_sizescan.npy', e_list)\n",
    "    np.save('data/s_list_sizescan.npy', s_list)\n",
    "    np.save('data/c_list_sizescan.npy', c_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the change in a thermodynamic quantity as a function of temperature as $n$ is increased by 1 (i.e., as the system size doubles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_n in range(len(n_list)-1):\n",
    "    plt.plot(th_beta_list, (np.mean(f_list, axis=1)[i_n+1] - np.mean(f_list, axis=1)[i_n])/np.mean(f_list, axis=1)[i_n], \n",
    "             label=r'$\\epsilon_{%i,%i}$' %(i_n+1,i_n))\n",
    "    plt.xlabel(r'$\\tanh(\\beta)$')\n",
    "    plt.title('Free Energy density')\n",
    "    plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_n in range(len(n_list)-1):\n",
    "    plt.plot(th_beta_list, (np.mean(c_list, axis=1)[i_n+1] - np.mean(c_list, axis=1)[i_n])/np.mean(c_list, axis=1)[i_n], \n",
    "             label=r'$\\epsilon_{%i,%i}$' %(i_n+1,i_n))\n",
    "    plt.xlabel(r'$\\tanh(\\beta)$')\n",
    "    plt.title('Heat Capacity density')\n",
    "    plt.legend()   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overlay curves for multiple system sizes to inspect convergence as $n \\rightarrow \\infty$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(2*11,2*9))\n",
    "ax = ax.flatten()\n",
    "\n",
    "## free energy\n",
    "for i_n in range(len(n_list)):\n",
    "    #ax[0].plot(th_beta_list, np.mean(f_list[i_n], axis=0), label=r'$n = %i\\, (N = %i)$'%(n_list[i_n], 2**n_list[i_n]))\n",
    "    ax[0].errorbar(th_beta_list, np.mean(f_list[i_n], axis=0), 1.96*sem(f_list[i_n], axis=0), fmt='--o', \\\n",
    "                   label=r'$n = %i\\, (N = %i)$'%(n_list[i_n], 2**n_list[i_n]))\n",
    "ax[0].set_xlabel(r'$\\tanh(\\beta)$')\n",
    "ax[0].set_title(r'Free Energy Density $F/N$')\n",
    "#ax[0].set_ylabel(r'$f$')\n",
    "ax[0].legend()\n",
    "\n",
    "## energy\n",
    "for i_n in range(len(n_list)):\n",
    "    #ax[1].plot(th_beta_list, np.mean(e_list[i_n], axis=0), label=r'$n = %i\\, (N = %i)$'%(n_list[i_n], 2**n_list[i_n]))\n",
    "    ax[1].errorbar(th_beta_list, np.mean(e_list[i_n], axis=0), 1.96*sem(e_list[i_n], axis=0), fmt='--o', \\\n",
    "                   label=r'$n = %i\\, (N = %i)$'%(n_list[i_n], 2**n_list[i_n]))    \n",
    "ax[1].set_xlabel(r'$\\tanh(\\beta)$')\n",
    "ax[1].set_title(r'Energy Density $\\langle E\\rangle/N$')\n",
    "#ax[1].set_ylabel(r'$f$')\n",
    "#ax[1].legend()\n",
    "\n",
    "## entropy\n",
    "for i_n in range(len(n_list)):\n",
    "#    ax[2].plot(th_beta_list, np.mean(s_list[i_n], axis=0), label=r'$n = %i\\, (N = %i)$'%(n_list[i_n], 2**n_list[i_n]))\n",
    "    ax[2].errorbar(th_beta_list, np.mean(s_list[i_n], axis=0), 1.96*sem(s_list[i_n], axis=0), fmt='--o', \\\n",
    "                   label=r'$n = %i\\, (N = %i)$'%(n_list[i_n], 2**n_list[i_n]))    \n",
    "ax[2].set_xlabel(r'$\\tanh(\\beta)$')\n",
    "ax[2].set_title(r'Entropy Density $S/N$')\n",
    "#ax[1].legend()\n",
    "\n",
    "for i_n in range(len(n_list)):\n",
    "#    ax[3].plot(th_beta_list, np.mean(c_list[i_n], axis=0), label=r'$n = %i\\, (N = %i)$'%(n_list[i_n], 2**n_list[i_n]))\n",
    "    ax[3].errorbar(th_beta_list, np.mean(c_list[i_n], axis=0), 1.96*sem(c_list[i_n], axis=0), fmt='--o', \\\n",
    "                   label=r'$n = %i\\, (N = %i)$'%(n_list[i_n], 2**n_list[i_n]))   \n",
    "ax[3].set_xlabel(r'$\\tanh(\\beta)$')\n",
    "ax[3].set_title(r'Heat Capacity Density $C/N$')\n",
    "\n",
    "'''\n",
    "for i_n in range(len(n_list)):\n",
    "    ax[4].errorbar(th_beta_list, np.mean(chi_list[i_n], axis=0), 1.96*sem(chi_list[i_n], axis=0), fmt='--o', \\\n",
    "                   label=r'$n = %i\\, (N = %i)$'%(n_list[i_n], 2**n_list[i_n]))   \n",
    "ax[4].set_xlabel(r'$\\tanh(\\beta)$')\n",
    "ax[4].set_title(r'$\\chi_{SG}$')\n",
    "'''\n",
    "\n",
    "## make sure the x tick marks extend to 1.0\n",
    "for i in range(len(ax)):\n",
    "    ax[i].xaxis.set_ticks(np.arange(0, 1.2, 0.2))\n",
    "\n",
    "plt.savefig('figures/disordered_model_thermodynamics.pdf', bbox_inches='tight', pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scan over disorder parameter space $(\\beta, p)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data, sigma=1):\n",
    "    '''\n",
    "    Helper function for processing the data and making it amenable for plotting.\n",
    "    Note that here the sigma parameter is NOT the same as the parameter used in \n",
    "    the hierarchical model; it is an argument to the gaussian_filter function.\n",
    "    '''\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "    \n",
    "    ## perform the disorder average\n",
    "    data = np.mean(data, axis=0)\n",
    "\n",
    "    ## perform gaussian smoothing to make nicer plots\n",
    "    ## the motivation for this came from this SE post: \n",
    "    ## https://stackoverflow.com/questions/12274529/how-to-smooth-matplotlib-contour-plot\n",
    "    data = scipy.ndimage.gaussian_filter(data, sigma)\n",
    "    \n",
    "    ## extract each individual point and add it to a list\n",
    "    for j in range(len(prob_list)):\n",
    "        for i in range(len(th_beta_list)):\n",
    "            x.append(th_beta_list[i])\n",
    "            y.append(prob_list[j])\n",
    "            z.append(data[i,j])\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    z = np.asarray(z)\n",
    "    \n",
    "    return x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grid = 100\n",
    "n_disorder = 100\n",
    "n = 9\n",
    "sigma = 0.0\n",
    "\n",
    "prob_list = np.linspace(0.05, 0.95, n_grid)\n",
    "th_beta_list = np.linspace(0.05, 0.95, n_grid)\n",
    "\n",
    "if os.path.exists('data/f_list_paramscan_n_%i.npy' %n):\n",
    "    print('data already exists, loading system size: N = %i, state space size = %.2e' % (2**n, 2**(2**n)))\n",
    "    f_list = np.load('data/f_list_paramscan_n_%i.npy' %n)\n",
    "    e_list = np.load('data/e_list_paramscan_n_%i.npy' %n)\n",
    "    s_list = np.load('data/s_list_paramscan_n_%i.npy' %n)\n",
    "    c_list = np.load('data/c_list_paramscan_n_%i.npy' %n)\n",
    "\n",
    "else:\n",
    "    print('data does not already exist, processing system size: N = %i, state space size = %.2e' % (2**n, 2**(2**n)))\n",
    "    f_list = onp.zeros((n_disorder, len(th_beta_list), len(prob_list)))\n",
    "    e_list = onp.zeros((n_disorder, len(th_beta_list), len(prob_list)))\n",
    "    s_list = onp.zeros((n_disorder, len(th_beta_list), len(prob_list)))\n",
    "    c_list = onp.zeros((n_disorder, len(th_beta_list), len(prob_list)))\n",
    "\n",
    "    ## loop over p values\n",
    "    counter = 0\n",
    "    t = time.time()\n",
    "    for i_p in tqdm(range(len(prob_list))):\n",
    "        prob = prob_list[i_p]\n",
    "\n",
    "        ## loop over disorder replicas\n",
    "        for k in range(n_disorder):\n",
    "            couplings = utils.generate_couplings(n, prob=prob, sigma=sigma)\n",
    "\n",
    "            ## loop over temperatures\n",
    "            for i_T in range(len(th_beta_list)):\n",
    "                beta = np.arctanh(th_beta_list[i_T])\n",
    "\n",
    "                f_list[k, i_T, i_p] = utils.free_energy(beta, couplings).item()/2**n\n",
    "                e_list[k, i_T, i_p] = utils.energy(beta, couplings).item()/2**n\n",
    "                s_list[k, i_T, i_p] = utils.entropy(beta, couplings).item()/2**n\n",
    "                c_list[k, i_T, i_p] = utils.heat_capacity(beta, couplings).item()/2**n\n",
    "\n",
    "        #print('iter %i/%i | time elapsed = %.2f s | prob = %.2f' %(counter, len(prob_list), time.time() - t, prob))\n",
    "        counter += 1\n",
    "        t = time.time()\n",
    "\n",
    "    ## save the results\n",
    "    np.save('data/f_list_paramscan_n_%i.npy' %n, f_list)\n",
    "    np.save('data/e_list_paramscan_n_%i.npy' %n, e_list)\n",
    "    np.save('data/s_list_paramscan_n_%i.npy' %n, s_list)\n",
    "    np.save('data/c_list_paramscan_n_%i.npy' %n, c_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "process the data by making mesh grids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [f_list, e_list, s_list, c_list]\n",
    "title_list = ['Free Energy density', 'Energy density', 'Entropy density', 'Heat Capacity density']\n",
    "\n",
    "## process the data\n",
    "z_list = []\n",
    "zi_list = []\n",
    "for i in range(4):\n",
    "    ## grab the data and arrange it into lists\n",
    "    x, y, z = process_data(data_list[i], sigma=2)\n",
    "    z_list.append(z)\n",
    "    \n",
    "    ## set up a regular grid of interpolation points    \n",
    "    ## use the same grid for all thermodynamic quantities\n",
    "    if i == 0:\n",
    "        ## original grid\n",
    "        #xi = x.reshape((n_grid, n_grid))\n",
    "        #yi = y.reshape((n_grid, n_grid))\n",
    "        \n",
    "        ## interpolated grid (smoother)\n",
    "        n_grid2 = 20\n",
    "        xi, yi = np.linspace(x.min(), x.max(), n_grid2), np.linspace(y.min(), y.max(), n_grid2)\n",
    "        xi, yi = np.meshgrid(xi, yi)\n",
    "\n",
    "    zi = scipy.interpolate.Rbf(x, y, z, function='linear')(xi, yi)\n",
    "    #zi = z.reshape((n_grid, n_grid))\n",
    "    zi_list.append(zi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make 3d surface plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cmap options\n",
    "#['viridis', 'plasma', 'inferno', 'magma', 'cividis']\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(2*11,2*9), subplot_kw=dict(projection='3d'))\n",
    "ax = ax.flatten()\n",
    "for i in range(4):\n",
    "    \n",
    "    ## grid/axis lines\n",
    "    #ax[i].w_xaxis.gridlines.set_lw(3.0)\n",
    "    #ax[i].w_yaxis.gridlines.set_lw(3.0)\n",
    "    #ax[i].w_zaxis.gridlines.set_lw(3.0)\n",
    "    #ax[i].w_xaxis.pane.set_color('black');\n",
    "    #ax[i].w_yaxis.pane.set_color('black');\n",
    "    #ax[i].w_zaxis.pane.set_color('black');\n",
    "    #ax[i].w_xaxis.line.set_color('black');\n",
    "    ax[i].xaxis._axinfo[\"grid\"].update({\"linewidth\":0.5, 'color':'black'})\n",
    "    ax[i].yaxis._axinfo[\"grid\"].update({\"linewidth\":0.5, 'color':'black'})\n",
    "    ax[i].zaxis._axinfo[\"grid\"].update({\"linewidth\":0.5, 'color':'black'})\n",
    "\n",
    "    ## plotting\n",
    "    #ax.plot_surface(xi, yi, zi)\n",
    "    #ax.contour3D(xi, yi, zi, 50, cmap='binary')\n",
    "    ax[i].plot_surface(xi, yi, zi_list[i], rstride=1, cstride=1, cmap='cividis', edgecolor='black')\n",
    "    #ax[i].plot_wireframe(xi, yi, zi_list[i], color='black', linewidth=0.5)\n",
    "    ax[i].set_xlabel(r'$\\tanh(\\beta J)$', labelpad=10)\n",
    "    ax[i].set_ylabel(r'$p$', labelpad=10)\n",
    "    ax[i].set_title(title_list[i])    \n",
    "    #ax[i].text(0.05, 0.975, s=abcs[i], size=24)\n",
    "    #ax[i].text2D(0.05, 0.95, \"2D Text\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/disordered_model_thermodynamic_surfaceplots.pdf', bbox_inches='tight', pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make 2d contour plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(2*9,2*9))\n",
    "ax = ax.flatten()\n",
    "\n",
    "for i in range(4):\n",
    "    ax[i].imshow(zi_list[i], \n",
    "                 vmin=zi_list[i].min(), \n",
    "                 vmax=zi_list[i].max(), \n",
    "                 origin='lower', \n",
    "                 extent=[x.min(), x.max(), y.min(), y.max()], \n",
    "                 interpolation='spline16',\n",
    "                 cmap='cividis')\n",
    "    #ax[i].scatter(x, y, c=z_list[i], s=20)    \n",
    "    contours = ax[i].contour(xi, yi, zi_list[i], 15, linestyles='-', colors='black')\n",
    "    ax[i].clabel(contours, inline=True, fontsize=12)\n",
    "    ax[i].set_xlabel(r'$\\tanh(\\beta J)$')\n",
    "    ax[i].set_ylabel(r'$p$')\n",
    "    ax[i].set_title(title_list[i])\n",
    "    ax[i].grid(visible=None)\n",
    "    ax[i].text(0.05, 0.975, abcs[i], size=24)\n",
    "#plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/disordered_model_thermodynamic_contourplots.pdf', bbox_inches='tight', pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spin-glass susceptibility\n",
    "\n",
    "The spin-glass susceptibility is defined as\n",
    "\n",
    "$$\\chi_{SG} = \\frac{\\beta^2}{N} \\sum_{ij} \\left[ \\langle s_i s_j \\rangle - \\langle s_i \\rangle \\langle s_j \\rangle \\right]^2 \\,. $$\n",
    "\n",
    "According to Mezard and Montanari, the finiteness of $\\chi_{SG}$ as $N \\rightarrow \\infty$ is a necessary (but not always sufficient) condition of the stability of the spin-glass phase. \n",
    "\n",
    "Here we can use Jax autodiff to both compute $\\chi_{SG}$ as well as the actual susceptibility matrix $\\chi_{SG} = \\langle s_i s_j \\rangle - \\langle s_i \\rangle \\langle s_j \\rangle$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_beta_list = np.asarray([0.05*i for i in range(1,20)])\n",
    "th_beta_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_list = np.asarray([0.05*i for i in range(1,20)])\n",
    "prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 9 #crashes with n=10, might be GPU limitation\n",
    "n_disorder = 100\n",
    "sigma = 0.0\n",
    "\n",
    "n_grid = len(th_beta_list)\n",
    "#n_grid = 10\n",
    "#th_beta_list = np.linspace(0.05, 0.95, n_grid)\n",
    "\n",
    "if os.path.exists('data/chi_SG_list_n_%i.npy' %n):\n",
    "    print('data already exists, loading system size: N = %i, state space size = %.2e' % (2**n, 2**(2**n)))\n",
    "    chi_SG_list = np.load('data/chi_SG_list_n_%i.npy' %n)\n",
    "    chi_eig_list = np.load('data/chi_eig_list_n_%i.npy' %n)\n",
    "\n",
    "else:\n",
    "    print('data does not already exist, processing system size: N = %i, state space size = %.2e' % (2**n, 2**(2**n)))\n",
    "    chi_SG_list = onp.zeros((n_disorder, len(prob_list), len(th_beta_list)))\n",
    "    chi_eig_list = onp.zeros((len(prob_list), len(th_beta_list), n_disorder, 2**n))\n",
    "\n",
    "    ## loop over probabilities\n",
    "    counter = 0\n",
    "    t = time.time()\n",
    "    for i_p in tqdm(range(len(prob_list))):\n",
    "\n",
    "        ## loop over disorder replicas\n",
    "        for k in range(n_disorder):\n",
    "            couplings = utils.generate_couplings(n, prob=prob_list[i_p], sigma=sigma)\n",
    "\n",
    "            ## loop over temperatures\n",
    "            for i_T in range(len(th_beta_list)):\n",
    "                beta = np.arctanh(th_beta_list[i_T])\n",
    "                chi_ij = utils.chi_ij(beta, couplings)\n",
    "                chi_SG_list[k, i_p, i_T] = beta**2 * np.sum(np.square(chi_ij))/2**n\n",
    "                chi_eig_list[i_p, i_T, k, :] = onp.real(onp.linalg.eig(chi_ij)[0])\n",
    "\n",
    "        #print('iter %i/%i | time elapsed = %.2f s' %(counter, n_disorder, time.time() - t))\n",
    "        counter += 1\n",
    "        t = time.time()\n",
    "\n",
    "    ## save the results\n",
    "    np.save('data/chi_SG_list_n_%i.npy' %n, chi_SG_list)\n",
    "    np.save('data/chi_eig_list_n_%i.npy' %n, chi_eig_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the spin-glass susceptibility as a function of temperature for a range of probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(11, 9))\n",
    "for i_p in [1, 3, 5, 7, 9, 11, 13, 15, 17]:\n",
    "    ax.errorbar(th_beta_list, np.mean(chi_SG_list[i_p], axis=0), 1.96*sem(chi_SG_list[i_p], axis=0), \n",
    "                fmt='--o', \n",
    "                markersize=6, \n",
    "                linewidth=3, \n",
    "                label=r'$p = %.2f$' %prob_list[i_p])\n",
    "ax.set_xlabel(r'$\\tanh(\\beta J)$')\n",
    "#plt.xticks(np.arange(0, 1.05, step=0.05), fontsize=10)\n",
    "ax.set_ylabel(r'$\\chi_{SG}$')\n",
    "ax.set_title('Spin Glass Susceptibility')\n",
    "#ax.text(0.0, 1.025, '(a)', size=24, transform=ax1.transAxes)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, make surface and contour plots as was done for the thermodynamic quantities above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## process the data\n",
    "z_list = []\n",
    "zi_list = []\n",
    "\n",
    "## grab the data and arrange it into lists\n",
    "y, x, z = process_data(chi_SG_list, sigma=2) #the temperature and prob axes are transposed relative to the above, hence the x<->y interchange\n",
    "z_list.append(z)\n",
    "\n",
    "## set up a regular grid of interpolation points    \n",
    "## use the same grid for all thermodynamic quantities\n",
    "if i == 0:\n",
    "    ## original grid\n",
    "    #xi = x.reshape((n_grid, n_grid))\n",
    "    #yi = y.reshape((n_grid, n_grid))\n",
    "\n",
    "    ## interpolated grid (smoother)\n",
    "    n_grid2 = 20\n",
    "    xi, yi = np.linspace(x.min(), x.max(), n_grid2), np.linspace(y.min(), y.max(), n_grid2)\n",
    "    xi, yi = np.meshgrid(xi, yi)\n",
    "\n",
    "zi = scipy.interpolate.Rbf(x, y, z, function='linear')(xi, yi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cmap options\n",
    "#['viridis', 'plasma', 'inferno', 'magma', 'cividis']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11,9), subplot_kw=dict(projection='3d'))\n",
    "ax.xaxis._axinfo[\"grid\"].update({\"linewidth\":0.5, 'color':'black'})\n",
    "ax.yaxis._axinfo[\"grid\"].update({\"linewidth\":0.5, 'color':'black'})\n",
    "ax.zaxis._axinfo[\"grid\"].update({\"linewidth\":0.5, 'color':'black'})\n",
    "ax.plot_surface(xi, yi, zi, rstride=1, cstride=1, cmap='cividis', edgecolor='black')\n",
    "ax.set_xlabel(r'$\\tanh(\\beta J)$', labelpad=10)\n",
    "ax.set_ylabel(r'$p$', labelpad=10)\n",
    "ax.set_title(r'$\\chi_{SG}$')    \n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/disordered_model_thermodynamic_chi_SG.pdf', bbox_inches='tight', pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9,9))\n",
    "ax.imshow(zi, \n",
    "         vmin=zi.min(), \n",
    "         vmax=zi.max(), \n",
    "         origin='lower', \n",
    "         extent=[x.min(), x.max(), y.min(), y.max()], \n",
    "         interpolation='spline16',\n",
    "         cmap='cividis')\n",
    "contours = ax.contour(xi, yi, zi, 15, linestyles='-', colors='black')\n",
    "ax.clabel(contours, inline=True, fontsize=12)\n",
    "ax.set_xlabel(r'$\\tanh(\\beta J)$')\n",
    "ax.set_ylabel(r'$p$')\n",
    "ax.set_title(r'$\\chi_{SG}$')\n",
    "ax.grid(visible=None)\n",
    "#ax.text(0.05, 0.975, abcs[i], size=24)\n",
    "#plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/disordered_model_thermodynamic_contourplots_chi_SG.pdf', bbox_inches='tight', pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, make plots of the distribution of $\\chi_{ij}$ eigenvalues. Start with histogram plots for a single probability (p=0.5). It will be convenient to restrict to a few select temperatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_beta_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_list = [1, 5, 9, 13, 17]\n",
    "[th_beta_list[i] for i in i_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_p = 9\n",
    "print('prob = %.2f' %prob_list[i_p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "alpha_hist = 1\n",
    "alpha_kde = 0.6\n",
    "\n",
    "## plot the histogram\n",
    "i = 0\n",
    "data = onp.asarray(chi_eig_list.reshape((len(prob_list), len(th_beta_list), n_disorder * 2**n))[i_p, i_list[i]])\n",
    "_, bins, _ = plt.hist(data, bins=100, range=[0, 2], \n",
    "                      histtype='step', \n",
    "                      linewidth=1.5, \n",
    "                      density=True, \n",
    "                      label=r'$\\tanh(\\beta J) = %.2f$' %th_beta_list[i_list[i]],\n",
    "                      alpha=alpha_hist)\n",
    "\n",
    "for i in range(1, len(i_list)):\n",
    "    data = onp.asarray(chi_eig_list.reshape((len(prob_list), len(th_beta_list), n_disorder * 2**n))[i_p, i_list[i]])\n",
    "    _ = plt.hist(data, bins=bins, \n",
    "                 histtype='step', \n",
    "                 linewidth=1.5, \n",
    "                 density=True, \n",
    "                 label=r'$\\tanh(\\beta J) = %.2f$' %th_beta_list[i_list[i]],\n",
    "                 alpha=alpha_hist)\n",
    "    \n",
    "## plot the kde\n",
    "plt.gca().set_prop_cycle(None)\n",
    "for i in range(len(i_list)):\n",
    "    data = onp.asarray(chi_eig_list.reshape((len(prob_list), len(th_beta_list), n_disorder * 2**n))[i_p, i_list[i]])\n",
    "    kde = scipy.stats.gaussian_kde(data)\n",
    "    xlin = np.linspace(0, 2, 500)\n",
    "    curve = kde(xlin)#*data.shape[0]\n",
    "    ax.fill_between(xlin, 0, curve, alpha=alpha_kde)#, label=r'$\\tanh(\\beta J) = %.2f$' %th_beta_list[k*i])\n",
    "plt.xlabel(r\"$\\chi_{p p'}$ eigenvalue\")\n",
    "plt.ylabel(r'Density')\n",
    "plt.legend(fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next just plot the histograms (no KDE plot overlayed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_hist = 0.6\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "## plot the histogram\n",
    "i = 0\n",
    "data = onp.asarray(chi_eig_list.reshape((len(prob_list), len(th_beta_list), n_disorder * 2**n))[i_p, i_list[i]])\n",
    "_, bins, _ = ax.hist(data, bins=150, range=[0, 2], \n",
    "                      histtype='bar', \n",
    "                      linewidth=2, \n",
    "                      density=True, \n",
    "                      label=r'$\\tanh(\\beta J) = %.2f$' %th_beta_list[i_list[i]],\n",
    "                      alpha=alpha_hist)\n",
    "\n",
    "for i in range(1, len(i_list)):\n",
    "    data = onp.asarray(chi_eig_list.reshape((len(prob_list), len(th_beta_list), n_disorder * 2**n))[i_p, i_list[i]])\n",
    "    _ = ax.hist(data, bins=bins, \n",
    "                 histtype='bar', \n",
    "                 linewidth=2, \n",
    "                 density=True, \n",
    "                 label=r'$\\tanh(\\beta J) = %.2f$' %th_beta_list[i_list[i]],\n",
    "                 alpha=alpha_hist)\n",
    "    \n",
    "plt.gca().set_prop_cycle(None)\n",
    "for i in range(0, len(i_list)):\n",
    "    data = onp.asarray(chi_eig_list.reshape((len(prob_list), len(th_beta_list), n_disorder * 2**n))[i_p, i_list[i]])\n",
    "    _ = ax.hist(data, bins=bins, \n",
    "                 histtype='step', \n",
    "                 linewidth=2, \n",
    "                 density=True)    \n",
    "    \n",
    "plt.xlabel(r\"$\\chi_{p p'}$ eigenvalue\")\n",
    "ax.set_ylabel(r'Density')\n",
    "ax.legend(fontsize=14)\n",
    "ax.set_title('Susceptibility Eigen-Spectrum')\n",
    "#ax.text(0.0, 1.025, '(b)', size=24, transform=ax.transAxes)\n",
    "\n",
    "plt.savefig('figures/disordered_model_chi.pdf', bbox_inches='tight', pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, combine the $\\chi_{SG}$ contour plot with the $\\chi_{ij}$ histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.min(), x.max(), y.min(), y.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(2*11,9), subplot_kw=dict(box_aspect=1))\n",
    "\n",
    "ax[0].imshow(zi, \n",
    "         vmin=zi.min(), \n",
    "         vmax=zi.max(), \n",
    "         origin='lower', \n",
    "         extent=[x.min(), x.max(), y.min(), y.max()], \n",
    "         interpolation='spline16',\n",
    "         cmap='cividis')\n",
    "contours = ax[0].contour(xi, yi, zi, 15, linestyles='-', colors='black')\n",
    "ax[0].clabel(contours, inline=True, fontsize=12)\n",
    "ax[0].set_xlabel(r'$\\tanh(\\beta J)$')\n",
    "ax[0].set_ylabel(r'$p$')\n",
    "ax[0].set_title(r'Spin-Glass Susceptibility $\\chi_{SG}$')\n",
    "ax[0].grid(visible=None)\n",
    "ax[0].text(0.05, 0.975, abcs[0], size=24)\n",
    "#ax[0].set_aspect('equal')\n",
    "\n",
    "## plot the histogram\n",
    "i = 0\n",
    "data = onp.asarray(chi_eig_list.reshape((len(prob_list), len(th_beta_list), n_disorder * 2**n))[i_p, i_list[i]])\n",
    "_, bins, _ = ax[1].hist(data, bins=150, range=[0, 2], \n",
    "                      histtype='bar', \n",
    "                      linewidth=2, \n",
    "                      density=True, \n",
    "                      label=r'$\\tanh(\\beta J) = %.2f$' %th_beta_list[i_list[i]],\n",
    "                      alpha=alpha_hist)\n",
    "\n",
    "for i in range(1, len(i_list)):\n",
    "    data = onp.asarray(chi_eig_list.reshape((len(prob_list), len(th_beta_list), n_disorder * 2**n))[i_p, i_list[i]])\n",
    "    _ = ax[1].hist(data, bins=bins, \n",
    "                 histtype='bar', \n",
    "                 linewidth=2, \n",
    "                 density=True, \n",
    "                 label=r'$\\tanh(\\beta J) = %.2f$' %th_beta_list[i_list[i]],\n",
    "                 alpha=alpha_hist)\n",
    "    \n",
    "plt.gca().set_prop_cycle(None)\n",
    "for i in range(0, len(i_list)):\n",
    "    data = onp.asarray(chi_eig_list.reshape((len(prob_list), len(th_beta_list), n_disorder * 2**n))[i_p, i_list[i]])\n",
    "    _ = ax[1].hist(data, bins=bins, \n",
    "                 histtype='step', \n",
    "                 linewidth=2, \n",
    "                 density=True)    \n",
    "    \n",
    "ax[1].set_xlabel(r\"$\\chi_{p p'}$ eigenvalue\")\n",
    "ax[1].set_ylabel(r'Density')\n",
    "ax[1].legend(fontsize=14)\n",
    "ax[1].set_title('Susceptibility Eigen-Spectrum')\n",
    "ax[1].text(0.0, 1.025, '(b)', size=24, transform=ax[1].transAxes)\n",
    "#ax[1].set_aspect('equal')\n",
    "\n",
    "#plt.tight_layout()\n",
    "plt.savefig('figures/disordered_model_chi.pdf', bbox_inches='tight', pad_inches=0)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "99f94bb265e4d3e6ea7d92675fd8bf5438ec24ed4296119f7a20dbca585e26d1"
  },
  "kernelspec": {
   "display_name": "Python 3.10.5 ('hierarchical')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "1adba3b2355880bd80be46a6f4dac2edd48e0700de3b88c7e5eb15080abd2e45"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
